{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Documentacion:** http://spark.apache.org/docs/latest/ml-features.html_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"LinearRegression\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----+\n",
      "|   Name|     Phone|Group|\n",
      "+-------+----------+-----+\n",
      "|   John|4085552424|    A|\n",
      "|   Mike|3105552738|    B|\n",
      "| Cassie|4085552424|    B|\n",
      "|  Laura|3105552438|    B|\n",
      "|  Sarah|4085551234|    A|\n",
      "|  David|3105557463|    C|\n",
      "|   Zach|4085553987|    C|\n",
      "|  Kiera|3105552938|    A|\n",
      "|  Alexa|4085559467|    C|\n",
      "|Karissa|3105553475|    A|\n",
      "+-------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(path = \"../data/fake_customers.csv\", \n",
    "                    inferSchema = True, header = True)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|Group|count|\n",
      "+-----+-----+\n",
      "|    B|    3|\n",
      "|    C|    3|\n",
      "|    A|    4|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Group').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StringIndexer\n",
    "\n",
    "Para transformar los valores categoricos a numericos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----+----------+\n",
      "|   Name|     Phone|Group|GroupIndex|\n",
      "+-------+----------+-----+----------+\n",
      "|   John|4085552424|    A|       0.0|\n",
      "|   Mike|3105552738|    B|       1.0|\n",
      "| Cassie|4085552424|    B|       1.0|\n",
      "|  Laura|3105552438|    B|       1.0|\n",
      "|  Sarah|4085551234|    A|       0.0|\n",
      "|  David|3105557463|    C|       2.0|\n",
      "|   Zach|4085553987|    C|       2.0|\n",
      "|  Kiera|3105552938|    A|       0.0|\n",
      "|  Alexa|4085559467|    C|       2.0|\n",
      "|Karissa|3105553475|    A|       0.0|\n",
      "+-------+----------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer1 = StringIndexer(inputCol = \"Group\",\n",
    "                         outputCol = \"GroupIndex\")\n",
    "\n",
    "indexed1 = indexer1.fit(df).transform(df)\n",
    "\n",
    "indexed1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----+----------+---------+\n",
      "|   Name|     Phone|Group|GroupIndex|NameIndex|\n",
      "+-------+----------+-----+----------+---------+\n",
      "|   John|4085552424|    A|       0.0|      3.0|\n",
      "|   Mike|3105552738|    B|       1.0|      7.0|\n",
      "| Cassie|4085552424|    B|       1.0|      1.0|\n",
      "|  Laura|3105552438|    B|       1.0|      6.0|\n",
      "|  Sarah|4085551234|    A|       0.0|      8.0|\n",
      "|  David|3105557463|    C|       2.0|      2.0|\n",
      "|   Zach|4085553987|    C|       2.0|      9.0|\n",
      "|  Kiera|3105552938|    A|       0.0|      5.0|\n",
      "|  Alexa|4085559467|    C|       2.0|      0.0|\n",
      "|Karissa|3105553475|    A|       0.0|      4.0|\n",
      "+-------+----------+-----+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer2 = StringIndexer(inputCol = \"Name\",\n",
    "                         outputCol = \"NameIndex\")\n",
    "\n",
    "indexed2 = indexer2.fit(indexed1).transform(indexed1)\n",
    "\n",
    "indexed2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T20:16:34.660394Z",
     "iopub.status.busy": "2021-11-28T20:16:34.660043Z",
     "iopub.status.idle": "2021-11-28T20:16:34.665394Z",
     "shell.execute_reply": "2021-11-28T20:16:34.664291Z",
     "shell.execute_reply.started": "2021-11-28T20:16:34.660358Z"
    }
   },
   "source": [
    "### VectorIndexer\n",
    "Para transformar los datos a un vector denso. Esto es obligatorio para los modelos de ML en PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------+--------------------+\n",
      "|     Phone|GroupIndex|NameIndex|            features|\n",
      "+----------+----------+---------+--------------------+\n",
      "|4085552424|       0.0|      3.0|[4.085552424E9,0....|\n",
      "|3105552738|       1.0|      7.0|[3.105552738E9,1....|\n",
      "|4085552424|       1.0|      1.0|[4.085552424E9,1....|\n",
      "|3105552438|       1.0|      6.0|[3.105552438E9,1....|\n",
      "|4085551234|       0.0|      8.0|[4.085551234E9,0....|\n",
      "|3105557463|       2.0|      2.0|[3.105557463E9,2....|\n",
      "|4085553987|       2.0|      9.0|[4.085553987E9,2....|\n",
      "|3105552938|       0.0|      5.0|[3.105552938E9,0....|\n",
      "|4085559467|       2.0|      0.0|[4.085559467E9,2....|\n",
      "|3105553475|       0.0|      4.0|[3.105553475E9,0....|\n",
      "+----------+----------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols = [\"Phone\", \"GroupIndex\", \"NameIndex\"],\n",
    "                            outputCol = \"features\")\n",
    "\n",
    "output = assembler.transform(indexed2)\n",
    "\n",
    "output.select([\"Phone\", \"GroupIndex\", \"NameIndex\", \"features\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Group</th>\n",
       "      <th>GroupIndex</th>\n",
       "      <th>NameIndex</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>4085552424</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[4085552424.0, 0.0, 3.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mike</td>\n",
       "      <td>3105552738</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[3105552738.0, 1.0, 7.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cassie</td>\n",
       "      <td>4085552424</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4085552424.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laura</td>\n",
       "      <td>3105552438</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[3105552438.0, 1.0, 6.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>4085551234</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[4085551234.0, 0.0, 8.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>David</td>\n",
       "      <td>3105557463</td>\n",
       "      <td>C</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[3105557463.0, 2.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zach</td>\n",
       "      <td>4085553987</td>\n",
       "      <td>C</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[4085553987.0, 2.0, 9.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kiera</td>\n",
       "      <td>3105552938</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[3105552938.0, 0.0, 5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alexa</td>\n",
       "      <td>4085559467</td>\n",
       "      <td>C</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[4085559467.0, 2.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Karissa</td>\n",
       "      <td>3105553475</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[3105553475.0, 0.0, 4.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name       Phone Group  GroupIndex  NameIndex                  features\n",
       "0     John  4085552424     A         0.0        3.0  [4085552424.0, 0.0, 3.0]\n",
       "1     Mike  3105552738     B         1.0        7.0  [3105552738.0, 1.0, 7.0]\n",
       "2   Cassie  4085552424     B         1.0        1.0  [4085552424.0, 1.0, 1.0]\n",
       "3    Laura  3105552438     B         1.0        6.0  [3105552438.0, 1.0, 6.0]\n",
       "4    Sarah  4085551234     A         0.0        8.0  [4085551234.0, 0.0, 8.0]\n",
       "5    David  3105557463     C         2.0        2.0  [3105557463.0, 2.0, 2.0]\n",
       "6     Zach  4085553987     C         2.0        9.0  [4085553987.0, 2.0, 9.0]\n",
       "7    Kiera  3105552938     A         0.0        5.0  [3105552938.0, 0.0, 5.0]\n",
       "8    Alexa  4085559467     C         2.0        0.0  [4085559467.0, 2.0, 0.0]\n",
       "9  Karissa  3105553475     A         0.0        4.0  [3105553475.0, 0.0, 4.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|              label|            features|\n",
      "+-------------------+--------------------+\n",
      "| -9.490009878824548|(10,[0,1,2,3,4,5,...|\n",
      "| 0.2577820163584905|(10,[0,1,2,3,4,5,...|\n",
      "| -4.438869807456516|(10,[0,1,2,3,4,5,...|\n",
      "|-19.782762789614537|(10,[0,1,2,3,4,5,...|\n",
      "| -7.966593841555266|(10,[0,1,2,3,4,5,...|\n",
      "| -7.896274316726144|(10,[0,1,2,3,4,5,...|\n",
      "| -8.464803554195287|(10,[0,1,2,3,4,5,...|\n",
      "| 2.1214592666251364|(10,[0,1,2,3,4,5,...|\n",
      "| 1.0720117616524107|(10,[0,1,2,3,4,5,...|\n",
      "|-13.772441561702871|(10,[0,1,2,3,4,5,...|\n",
      "| -5.082010756207233|(10,[0,1,2,3,4,5,...|\n",
      "|  7.887786536531237|(10,[0,1,2,3,4,5,...|\n",
      "| 14.323146365332388|(10,[0,1,2,3,4,5,...|\n",
      "|-20.057482615789212|(10,[0,1,2,3,4,5,...|\n",
      "|-0.8995693247765151|(10,[0,1,2,3,4,5,...|\n",
      "| -19.16829262296376|(10,[0,1,2,3,4,5,...|\n",
      "|  5.601801561245534|(10,[0,1,2,3,4,5,...|\n",
      "|-3.2256352187273354|(10,[0,1,2,3,4,5,...|\n",
      "| 1.5299675726687754|(10,[0,1,2,3,4,5,...|\n",
      "| -0.250102447941961|(10,[0,1,2,3,4,5,...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.format(\"libsvm\").load(\"../data/sample_linear_regression_data.txt\")\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es el formato que Spark usa para hacer ML, dos columnas, una llamada \"label\" y otra de \"features\", que serían \"y\" y \"X\" respectivamente.\n",
    "\n",
    "La columna \"label\" o \"y\" debe ser una columna numerica, al igual que cuando haciamos modelos de SciKit-Learn.\n",
    "\n",
    "La columna \"features\" o \"X\" esta formada por vectores , estos vectores son los elementos agrupados de las columnas iniciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inicializamos el modelo\n",
    "lr = LinearRegression(featuresCol = \"features\",\n",
    "                      labelCol = \"label\",\n",
    "                      predictionCol = \"prediction\")\n",
    "\n",
    "# Nota: si en el DataFrame las columnas tienen otros nombres podemos decirle al modelo que trabaje con esos nombres\n",
    "# Por convencion \"X\" se llama \"features\", \"y\" se llama \"label\" y las predicciones se llaman \"prediction\"\n",
    "# Y esos son los valores por defecto de los modelo de ML.\n",
    "\n",
    "# Entrenamos el modelo \n",
    "model = lr.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes: [0.0073350710225801715,0.8313757584337543,-0.8095307954684084,2.441191686884721,0.5191713795290003,1.1534591903547016,-0.2989124112808717,-0.5128514186201779,-0.619712827067017,0.6956151804322931]\n",
      "\n",
      "\n",
      "Intercepcion:0.14228558260358093\n"
     ]
    }
   ],
   "source": [
    "# Podemos imprimir los coeficientes de la regresion\n",
    "print(\"Coeficientes: {}\".format(str(model.coefficients)))\n",
    "print(\"\\n\")\n",
    "print(\"Intercepcion:{}\".format(str(model.intercept)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# El modelo tiene el metodo .summary\n",
    "# Este summary se hace sobre el set de entrenamiento y calcula las metricas del modelo\n",
    "sumario = model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          residuals|\n",
      "+-------------------+\n",
      "|-11.011130022096554|\n",
      "| 0.9236590911176538|\n",
      "|-4.5957401897776675|\n",
      "|  -20.4201774575836|\n",
      "|-10.339160314788181|\n",
      "|-5.9552091439610555|\n",
      "|-10.726906349283922|\n",
      "|  2.122807193191233|\n",
      "|  4.077122222293811|\n",
      "|-17.316168071241652|\n",
      "| -4.593044343959059|\n",
      "|  6.380476690746936|\n",
      "| 11.320566035059846|\n",
      "|-20.721971774534094|\n",
      "| -2.736692773777401|\n",
      "| -16.66886934252847|\n",
      "|  8.242186378876315|\n",
      "|-1.3723486332690233|\n",
      "|-0.7060332131264666|\n",
      "|-1.1591135969994064|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RMSE: 10.16309157133015\n",
      "r2: 0.027839179518600154\n"
     ]
    }
   ],
   "source": [
    "sumario.residuals.show()\n",
    "# .residuals es la diferencia entre el valor real y el valor predicho \n",
    "\n",
    "print(\"RMSE: {}\".format(sumario.rootMeanSquaredError))\n",
    "print(\"r2: {}\".format(sumario.r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "\n",
    "No existe la función **train_test_split**... Pero los objetos DataFrames de Spark tienen un método que hace lo mismo que **train_test_split**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+\n",
      "|             label|            features|\n",
      "+------------------+--------------------+\n",
      "|-9.490009878824548|(10,[0,1,2,3,4,5,...|\n",
      "|0.2577820163584905|(10,[0,1,2,3,4,5,...|\n",
      "|-4.438869807456516|(10,[0,1,2,3,4,5,...|\n",
      "+------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# .randomSplit()\n",
    "\n",
    "train, test = data.randomSplit(weights = [0.7, 0.3], seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|              label|            features|\n",
      "+-------------------+--------------------+\n",
      "|-28.571478869743427|(10,[0,1,2,3,4,5,...|\n",
      "|-28.046018037776633|(10,[0,1,2,3,4,5,...|\n",
      "|-26.736207182601724|(10,[0,1,2,3,4,5,...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-------------------+--------------------+\n",
      "|              label|            features|\n",
      "+-------------------+--------------------+\n",
      "|-26.805483428483072|(10,[0,1,2,3,4,5,...|\n",
      "|-22.949825936196074|(10,[0,1,2,3,4,5,...|\n",
      "|-21.432387764165806|(10,[0,1,2,3,4,5,...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(3)\n",
    "\n",
    "test.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(10, {0: -0.4597, 1: -0.5489, 2: 0.3342, 3: -0.1599, 4: -0.731, 5: 0.1824, 6: -0.4839, 7: 0.0814, 8: -0.8401, 9: -0.8896})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select('features').collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07273225877410616"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_hat = model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.14679155085585793"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-26.805483</td>\n",
       "      <td>(0.4572552704218824, -0.576096954000229, -0.20...</td>\n",
       "      <td>1.500419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-22.949826</td>\n",
       "      <td>(0.4797855980916854, 0.01997502546020402, -0.8...</td>\n",
       "      <td>6.540722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-21.432388</td>\n",
       "      <td>(-0.4785033857256795, 0.520350718059089, -0.29...</td>\n",
       "      <td>1.436978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-20.212077</td>\n",
       "      <td>(0.5609065808412279, -0.9201904391147984, 0.90...</td>\n",
       "      <td>1.315605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-19.782763</td>\n",
       "      <td>(-0.0388509668871313, -0.4166870051763918, 0.8...</td>\n",
       "      <td>-0.095102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>17.403292</td>\n",
       "      <td>(0.9155980216177384, -0.35593866074295355, 0.4...</td>\n",
       "      <td>-2.867510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>18.479681</td>\n",
       "      <td>(0.9635517137863321, 0.9954507816218203, 0.119...</td>\n",
       "      <td>2.136439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>19.341343</td>\n",
       "      <td>(-0.32052868280788616, 0.954507993011956, 0.38...</td>\n",
       "      <td>2.736410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>20.456948</td>\n",
       "      <td>(-0.21923785332346513, 0.11340668617783778, 0....</td>\n",
       "      <td>-2.750814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>23.529454</td>\n",
       "      <td>(-0.12339549394875426, -0.6769524283089239, 0....</td>\n",
       "      <td>0.833063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                           features  prediction\n",
       "0   -26.805483  (0.4572552704218824, -0.576096954000229, -0.20...    1.500419\n",
       "1   -22.949826  (0.4797855980916854, 0.01997502546020402, -0.8...    6.540722\n",
       "2   -21.432388  (-0.4785033857256795, 0.520350718059089, -0.29...    1.436978\n",
       "3   -20.212077  (0.5609065808412279, -0.9201904391147984, 0.90...    1.315605\n",
       "4   -19.782763  (-0.0388509668871313, -0.4166870051763918, 0.8...   -0.095102\n",
       "..         ...                                                ...         ...\n",
       "121  17.403292  (0.9155980216177384, -0.35593866074295355, 0.4...   -2.867510\n",
       "122  18.479681  (0.9635517137863321, 0.9954507816218203, 0.119...    2.136439\n",
       "123  19.341343  (-0.32052868280788616, 0.954507993011956, 0.38...    2.736410\n",
       "124  20.456948  (-0.21923785332346513, 0.11340668617783778, 0....   -2.750814\n",
       "125  23.529454  (-0.12339549394875426, -0.6769524283089239, 0....    0.833063\n",
       "\n",
       "[126 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.predictions.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          residuals|\n",
      "+-------------------+\n",
      "|-28.305902730922302|\n",
      "|-29.490547492772325|\n",
      "| -22.86936529151847|\n",
      "|-21.527682553818114|\n",
      "|-19.687660427789638|\n",
      "| -19.79380269286442|\n",
      "|-18.994876037916928|\n",
      "|-16.420875732937652|\n",
      "|  -20.1251816195632|\n",
      "|-19.488242333300025|\n",
      "|-16.690287207468383|\n",
      "|-17.732540358670345|\n",
      "| -15.17297252570881|\n",
      "|-13.517777209767612|\n",
      "|-20.504549034361794|\n",
      "| -17.52072428950006|\n",
      "| -15.06463157411349|\n",
      "|-18.728361362879223|\n",
      "|-15.995976443402697|\n",
      "| -15.16368146542394|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RMSE: 11.929738804585622\n"
     ]
    }
   ],
   "source": [
    "y_hat.residuals.show()\n",
    "print(\"RMSE: {}\".format(y_hat.rootMeanSquaredError))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta aquí llegaría el modelo, ahora vamos a ver como hacer predicciones de datos nuevos.\n",
    "\n",
    "Vamos a trabajar con la columna de \"features\" de test, así solo nos quedamos con \"X\" y no sabemos el valor de \"y\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.14679155085585793"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nueva_data = test.select(\"features\")\n",
    "nueva_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            features|          prediction|\n",
      "+--------------------+--------------------+\n",
      "|(10,[0,1,2,3,4,5,...|   1.500419302439231|\n",
      "|(10,[0,1,2,3,4,5,...|   6.540721556576252|\n",
      "|(10,[0,1,2,3,4,5,...|  1.4369775273526635|\n",
      "|(10,[0,1,2,3,4,5,...|  1.3156052948594428|\n",
      "|(10,[0,1,2,3,4,5,...|-0.09510236182489817|\n",
      "|(10,[0,1,2,3,4,5,...| 0.12648407749270263|\n",
      "|(10,[0,1,2,3,4,5,...|-0.40745999229762575|\n",
      "|(10,[0,1,2,3,4,5,...| -1.3827504557268635|\n",
      "|(10,[0,1,2,3,4,5,...|  2.6965070486236957|\n",
      "|(10,[0,1,2,3,4,5,...|    2.42284270742401|\n",
      "|(10,[0,1,2,3,4,5,...|-0.33620505674116263|\n",
      "|(10,[0,1,2,3,4,5,...|  1.5811910073932323|\n",
      "|(10,[0,1,2,3,4,5,...| -0.9126865153126812|\n",
      "|(10,[0,1,2,3,4,5,...| -2.4337353560269603|\n",
      "|(10,[0,1,2,3,4,5,...|  4.7238640017384945|\n",
      "|(10,[0,1,2,3,4,5,...|  1.7972086764514907|\n",
      "|(10,[0,1,2,3,4,5,...| -0.3727532193177282|\n",
      "|(10,[0,1,2,3,4,5,...|   3.393593882956883|\n",
      "|(10,[0,1,2,3,4,5,...|   1.173823533651508|\n",
      "|(10,[0,1,2,3,4,5,...| 0.40092321249281315|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# En lugar de usar .evaluate() vamos a usar .transform() y esto nos retorna un nuevo DataFrame\n",
    "y_hat = model.transform(nueva_data)\n",
    "y_hat.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(path = \"modelo.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackaboss",
   "language": "python",
   "name": "hackaboss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
