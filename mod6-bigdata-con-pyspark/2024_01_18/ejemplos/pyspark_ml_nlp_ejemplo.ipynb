{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"NLP\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|_c0 |_c1                                                                                                                                                        |\n",
      "+----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ham |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            |\n",
      "|ham |Ok lar... Joking wif u oni...                                                                                                                              |\n",
      "|spam|Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's|\n",
      "|ham |U dun say so early hor... U c already then say...                                                                                                          |\n",
      "|ham |Nah I don't think he goes to usf, he lives around here though                                                                                              |\n",
      "+----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv(\"../../data/SMSSpamCollection\",\n",
    "                      inferSchema = True, sep = \"\\t\")\n",
    "\n",
    "data.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|class|text                                                                                                                                                       |\n",
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ham  |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            |\n",
      "|ham  |Ok lar... Joking wif u oni...                                                                                                                              |\n",
      "|spam |Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's|\n",
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.withColumnRenamed(existing = \"_c0\", new = \"class\")\\\n",
    "           .withColumnRenamed(existing = \"_c1\", new = \"text\")\n",
    "\n",
    "data.show(3, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+\n",
      "|class|                text|length|\n",
      "+-----+--------------------+------+\n",
      "|  ham|Go until jurong p...|   111|\n",
      "|  ham|Ok lar... Joking ...|    29|\n",
      "| spam|Free entry in 2 a...|   155|\n",
      "|  ham|U dun say so earl...|    49|\n",
      "|  ham|Nah I don't think...|    61|\n",
      "| spam|FreeMsg Hey there...|   147|\n",
      "|  ham|Even my brother i...|    77|\n",
      "|  ham|As per your reque...|   160|\n",
      "| spam|WINNER!! As a val...|   157|\n",
      "| spam|Had your mobile 1...|   154|\n",
      "|  ham|I'm gonna be home...|   109|\n",
      "| spam|SIX chances to wi...|   136|\n",
      "| spam|URGENT! You have ...|   155|\n",
      "|  ham|I've been searchi...|   196|\n",
      "|  ham|I HAVE A DATE ON ...|    35|\n",
      "| spam|XXXMobileMovieClu...|   149|\n",
      "|  ham|Oh k...i'm watchi...|    26|\n",
      "|  ham|Eh u remember how...|    81|\n",
      "|  ham|Fine if thats th...|    56|\n",
      "| spam|England v Macedon...|   155|\n",
      "+-----+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import length\n",
    "\n",
    "data = data.withColumn(colName = \"length\", col = length(data[\"text\"]))\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|class|      avg(length)|\n",
      "+-----+-----------------+\n",
      "|  ham|71.45431945307645|\n",
      "| spam|138.6706827309237|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupby(\"class\").mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol = \"text\",\n",
    "                      outputCol = \"token_text\") # tokenizamos las sentencias\n",
    "\n",
    "remover = StopWordsRemover(inputCol = \"token_text\",\n",
    "                           outputCol = \"stop_tokens\") #eliminamos stop words\n",
    "\n",
    "cv = CountVectorizer(inputCol = \"stop_tokens\",\n",
    "                            outputCol = \"count_vec\") # le pasamos el countventorizer\n",
    "\n",
    "idf = IDF(inputCol = \"count_vec\",\n",
    "          outputCol = \"tf_idf\") # transformamos con IDF\n",
    "\n",
    "class_indexer = StringIndexer(inputCol = \"class\",\n",
    "                              outputCol = \"label\") # label encoder para codificar nuestras clases\n",
    "\n",
    "assembler = VectorAssembler(inputCols = [\"tf_idf\", \"length\"],\n",
    "                            outputCol = \"features\") # constructor del sparsher vector\n",
    "\n",
    "scaler = StandardScaler(inputCol = \"features\",\n",
    "                        outputCol = \"scaled_features\",\n",
    "                        withStd = True,\n",
    "                        withMean = False) # aplicamos el standar scaler a nuestros datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "nb = NaiveBayes(featuresCol = \"scaled_features\",\n",
    "                labelCol = \"label\",\n",
    "                predictionCol = \"prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|class|                text|length|label|          token_text|         stop_tokens|           count_vec|              tf_idf|            features|     scaled_features|\n",
      "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  ham|Go until jurong p...|   111|  0.0|[go, until, juron...|[go, jurong, poin...|(13423,[7,11,31,6...|(13423,[7,11,31,6...|(13424,[7,11,31,6...|(13424,[7,11,31,6...|\n",
      "|  ham|Ok lar... Joking ...|    29|  0.0|[ok, lar..., joki...|[ok, lar..., joki...|(13423,[0,24,297,...|(13423,[0,24,297,...|(13424,[0,24,297,...|(13424,[0,24,297,...|\n",
      "| spam|Free entry in 2 a...|   155|  1.0|[free, entry, in,...|[free, entry, 2, ...|(13423,[2,13,19,3...|(13423,[2,13,19,3...|(13424,[2,13,19,3...|(13424,[2,13,19,3...|\n",
      "|  ham|U dun say so earl...|    49|  0.0|[u, dun, say, so,...|[u, dun, say, ear...|(13423,[0,70,80,1...|(13423,[0,70,80,1...|(13424,[0,70,80,1...|(13424,[0,70,80,1...|\n",
      "|  ham|Nah I don't think...|    61|  0.0|[nah, i, don't, t...|[nah, think, goes...|(13423,[36,134,31...|(13423,[36,134,31...|(13424,[36,134,31...|(13424,[36,134,31...|\n",
      "| spam|FreeMsg Hey there...|   147|  1.0|[freemsg, hey, th...|[freemsg, hey, da...|(13423,[10,60,139...|(13423,[10,60,139...|(13424,[10,60,139...|(13424,[10,60,139...|\n",
      "|  ham|Even my brother i...|    77|  0.0|[even, my, brothe...|[even, brother, l...|(13423,[10,53,103...|(13423,[10,53,103...|(13424,[10,53,103...|(13424,[10,53,103...|\n",
      "|  ham|As per your reque...|   160|  0.0|[as, per, your, r...|[per, request, 'm...|(13423,[125,184,4...|(13423,[125,184,4...|(13424,[125,184,4...|(13424,[125,184,4...|\n",
      "| spam|WINNER!! As a val...|   157|  1.0|[winner!!, as, a,...|[winner!!, valued...|(13423,[1,47,118,...|(13423,[1,47,118,...|(13424,[1,47,118,...|(13424,[1,47,118,...|\n",
      "| spam|Had your mobile 1...|   154|  1.0|[had, your, mobil...|[mobile, 11, mont...|(13423,[0,1,13,27...|(13423,[0,1,13,27...|(13424,[0,1,13,27...|(13424,[0,1,13,27...|\n",
      "|  ham|I'm gonna be home...|   109|  0.0|[i'm, gonna, be, ...|[gonna, home, soo...|(13423,[18,43,120...|(13423,[18,43,120...|(13424,[18,43,120...|(13424,[18,43,120...|\n",
      "| spam|SIX chances to wi...|   136|  1.0|[six, chances, to...|[six, chances, wi...|(13423,[8,17,37,8...|(13423,[8,17,37,8...|(13424,[8,17,37,8...|(13424,[8,17,37,8...|\n",
      "| spam|URGENT! You have ...|   155|  1.0|[urgent!, you, ha...|[urgent!, won, 1,...|(13423,[13,30,47,...|(13423,[13,30,47,...|(13424,[13,30,47,...|(13424,[13,30,47,...|\n",
      "|  ham|I've been searchi...|   196|  0.0|[i've, been, sear...|[searching, right...|(13423,[39,96,217...|(13423,[39,96,217...|(13424,[39,96,217...|(13424,[39,96,217...|\n",
      "|  ham|I HAVE A DATE ON ...|    35|  0.0|[i, have, a, date...|[date, sunday, wi...|(13423,[552,1697,...|(13423,[552,1697,...|(13424,[552,1697,...|(13424,[552,1697,...|\n",
      "| spam|XXXMobileMovieClu...|   149|  1.0|[xxxmobilemoviecl...|[xxxmobilemoviecl...|(13423,[30,109,11...|(13423,[30,109,11...|(13424,[30,109,11...|(13424,[30,109,11...|\n",
      "|  ham|Oh k...i'm watchi...|    26|  0.0|[oh, k...i'm, wat...|[oh, k...i'm, wat...|(13423,[82,214,47...|(13423,[82,214,47...|(13424,[82,214,47...|(13424,[82,214,47...|\n",
      "|  ham|Eh u remember how...|    81|  0.0|[eh, u, remember,...|[eh, u, remember,...|(13423,[0,2,49,13...|(13423,[0,2,49,13...|(13424,[0,2,49,13...|(13424,[0,2,49,13...|\n",
      "|  ham|Fine if thats th...|    56|  0.0|[fine, if, thats...|[fine, thats, wa...|(13423,[0,74,105,...|(13423,[0,74,105,...|(13424,[0,74,105,...|(13424,[0,74,105,...|\n",
      "| spam|England v Macedon...|   155|  1.0|[england, v, mace...|[england, v, mace...|(13423,[4,30,33,5...|(13423,[4,30,33,5...|(13424,[4,30,33,5...|(13424,[4,30,33,5...|\n",
      "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "data_pipeline = Pipeline(stages = [class_indexer, tokenizer, remover, cv, idf, assembler, scaler])\n",
    "\n",
    "df = data_pipeline.fit(data).transform(data)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|     scaled_features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(13424,[7,11,31,6...|\n",
      "|  0.0|(13424,[0,24,297,...|\n",
      "|  1.0|(13424,[2,13,19,3...|\n",
      "|  0.0|(13424,[0,70,80,1...|\n",
      "|  0.0|(13424,[36,134,31...|\n",
      "|  1.0|(13424,[10,60,139...|\n",
      "|  0.0|(13424,[10,53,103...|\n",
      "|  0.0|(13424,[125,184,4...|\n",
      "|  1.0|(13424,[1,47,118,...|\n",
      "|  1.0|(13424,[0,1,13,27...|\n",
      "|  0.0|(13424,[18,43,120...|\n",
      "|  1.0|(13424,[8,17,37,8...|\n",
      "|  1.0|(13424,[13,30,47,...|\n",
      "|  0.0|(13424,[39,96,217...|\n",
      "|  0.0|(13424,[552,1697,...|\n",
      "|  1.0|(13424,[30,109,11...|\n",
      "|  0.0|(13424,[82,214,47...|\n",
      "|  0.0|(13424,[0,2,49,13...|\n",
      "|  0.0|(13424,[0,74,105,...|\n",
      "|  1.0|(13424,[4,30,33,5...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select(\"label\", \"scaled_features\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test = df.randomSplit(weights = [0.7, 0.3], seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|     scaled_features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(13424,[0,1,2,41,...|[-6226.5365510546...|[1.0,3.3317145166...|       0.0|\n",
      "|  0.0|(13424,[0,1,5,20,...|[-2988.9347593964...|[1.0,1.5042166897...|       0.0|\n",
      "|  0.0|(13424,[0,1,7,8,1...|[-5712.5187450676...|           [1.0,0.0]|       0.0|\n",
      "|  0.0|(13424,[0,1,7,15,...|[-2093.1648499213...|[1.0,2.2619322386...|       0.0|\n",
      "|  0.0|(13424,[0,1,12,33...|[-1203.2516574584...|[1.0,4.9040892080...|       0.0|\n",
      "|  0.0|(13424,[0,1,14,18...|[-8246.6942360396...|[1.0,1.8263902087...|       0.0|\n",
      "|  0.0|(13424,[0,1,14,31...|[-351.55828013012...|[1.0,1.2459092621...|       0.0|\n",
      "|  0.0|(13424,[0,1,18,20...|[-3498.1648008885...|[1.0,2.1889348879...|       0.0|\n",
      "|  0.0|(13424,[0,1,21,27...|[-2159.7887451919...|[1.0,6.0675741146...|       0.0|\n",
      "|  0.0|(13424,[0,1,23,63...|[-6419.3478176448...|[1.0,4.1246340507...|       0.0|\n",
      "|  0.0|(13424,[0,1,24,31...|[-969.56923175523...|[1.0,6.0182467221...|       0.0|\n",
      "|  0.0|(13424,[0,1,31,43...|[-912.93194552091...|[1.0,7.6344982508...|       0.0|\n",
      "|  0.0|(13424,[0,1,43,69...|[-3935.9664278501...|[9.20104420085910...|       1.0|\n",
      "|  0.0|(13424,[0,1,46,17...|[-8942.9659343919...|[4.27360319825797...|       1.0|\n",
      "|  0.0|(13424,[0,1,146,1...|[-1427.8764415151...|[1.41518946176384...|       1.0|\n",
      "|  0.0|(13424,[0,1,498,5...|[-1616.9784932782...|[1.0,6.6975971292...|       0.0|\n",
      "|  0.0|(13424,[0,1,874,1...|[-251.97824587859...|[1.0,2.7968348164...|       0.0|\n",
      "|  0.0|(13424,[0,2,3,5,6...|[-13943.641923925...|[1.0,4.1702000613...|       0.0|\n",
      "|  0.0|(13424,[0,2,3,6,9...|[-13436.295846347...|           [1.0,0.0]|       0.0|\n",
      "|  0.0|(13424,[0,2,3,6,9...|[-13436.295846347...|           [1.0,0.0]|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = nb.fit(train)\n",
    "\n",
    "y_hat = model.transform(test)\n",
    "\n",
    "y_hat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8060263653483992"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol = \"prediction\", \n",
    "                                              labelCol = \"label\",\n",
    "                                              metricName = \"accuracy\")\n",
    "accuracy = evaluator.evaluate(y_hat)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8344303522772644"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_evaluator = MulticlassClassificationEvaluator(predictionCol = \"prediction\", \n",
    "                                              labelCol = \"label\",\n",
    "                                              metricName = \"f1\")\n",
    "f1 = f1_evaluator.evaluate(y_hat)\n",
    "\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haciendo la división de Train-Test antes de escalar y transformar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data.randomSplit(weights = [0.7, 0.3], seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|class|                text|length|label|          token_text|         stop_tokens|           count_vec|              tf_idf|            features|     scaled_features|\n",
      "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  ham| &lt;#&gt;  in mc...|    36|  0.0|[, &lt;#&gt;, , i...|[, &lt;#&gt;, , m...|(11001,[3,8,2824,...|(11001,[3,8,2824,...|(11002,[3,8,2824,...|(11002,[3,8,2824,...|\n",
      "|  ham| &lt;#&gt;  mins ...|    51|  0.0|[, &lt;#&gt;, , m...|[, &lt;#&gt;, , m...|(11001,[3,8,42,20...|(11001,[3,8,42,20...|(11002,[3,8,42,20...|(11002,[3,8,42,20...|\n",
      "|  ham| and  picking the...|    41|  0.0|[, and, , picking...|[, , picking, var...|(11001,[3,887,316...|(11001,[3,887,316...|(11002,[3,887,316...|(11002,[3,887,316...|\n",
      "|  ham| came to look at ...|   103|  0.0|[, came, to, look...|[, came, look, fl...|(11001,[3,11,160,...|(11001,[3,11,160,...|(11002,[3,11,160,...|(11002,[3,11,160,...|\n",
      "|  ham| gonna let me kno...|    95|  0.0|[, gonna, let, me...|[, gonna, let, kn...|(11001,[3,13,72,8...|(11001,[3,13,72,8...|(11002,[3,13,72,8...|(11002,[3,13,72,8...|\n",
      "|  ham| says that he's q...|   200|  0.0|[, says, that, he...|[, says, quitting...|(11001,[0,3,12,17...|(11001,[0,3,12,17...|(11002,[0,3,12,17...|(11002,[0,3,12,17...|\n",
      "|  ham|\"Happy valentines...|   147|  0.0|[\"happy, valentin...|[\"happy, valentin...|(11001,[13,153,16...|(11001,[13,153,16...|(11002,[13,153,16...|(11002,[13,153,16...|\n",
      "|  ham|\"Its Ur luck to L...|   155|  0.0|[\"its, ur, luck, ...|[\"its, ur, luck, ...|(11001,[4,22,28,9...|(11001,[4,22,28,9...|(11002,[4,22,28,9...|(11002,[4,22,28,9...|\n",
      "|  ham|\"Life is nothing ...|   159|  0.0|[\"life, is, nothi...|[\"life, nothing, ...|(11001,[5,61,97,1...|(11001,[5,61,97,1...|(11002,[5,61,97,1...|(11002,[5,61,97,1...|\n",
      "|  ham|\"The world suffer...|   129|  0.0|[\"the, world, suf...|[\"the, world, suf...|(11001,[15,97,334...|(11001,[15,97,334...|(11002,[15,97,334...|(11002,[15,97,334...|\n",
      "|  ham|\"Wen u miss someo...|   143|  0.0|[\"wen, u, miss, s...|[\"wen, u, miss, s...|(11001,[0,61,221,...|(11001,[0,61,221,...|(11002,[0,61,221,...|(11002,[0,61,221,...|\n",
      "|  ham|&lt;#&gt;  am I t...|    45|  0.0|[&lt;#&gt;, , am,...|[&lt;#&gt;, , thi...|(11001,[3,8,77,39...|(11001,[3,8,77,39...|(11002,[3,8,77,39...|(11002,[3,8,77,39...|\n",
      "|  ham|&lt;#&gt;  is fas...|   461|  0.0|[&lt;#&gt;, , is,...|[&lt;#&gt;, , fas...|(11001,[0,3,7,8,1...|(11001,[0,3,7,8,1...|(11002,[0,3,7,8,1...|(11002,[0,3,7,8,1...|\n",
      "|  ham|&lt;#&gt; %of ppl...|   327|  0.0|[&lt;#&gt;, %of, ...|[&lt;#&gt;, %of, ...|(11001,[0,2,3,5,8...|(11001,[0,2,3,5,8...|(11002,[0,2,3,5,8...|(11002,[0,2,3,5,8...|\n",
      "|  ham|'An Amazing Quote...|   141|  0.0|['an, amazing, qu...|['an, amazing, qu...|(11001,[71,158,20...|(11001,[71,158,20...|(11002,[71,158,20...|(11002,[71,158,20...|\n",
      "|  ham|'Wnevr i wana fal...|   155|  0.0|['wnevr, i, wana,...|['wnevr, wana, fa...|(11001,[9,97,197,...|(11001,[9,97,197,...|(11002,[9,97,197,...|(11002,[9,97,197,...|\n",
      "|  ham|(And my man carlo...|    66|  0.0|[(and, my, man, c...|[(and, man, carlo...|(11001,[160,270,6...|(11001,[160,270,6...|(11002,[160,270,6...|(11002,[160,270,6...|\n",
      "|  ham|(You didn't hear ...|    28|  0.0|[(you, didn't, he...|   [(you, hear, me)]|(11001,[271,5415,...|(11001,[271,5415,...|(11002,[271,5415,...|(11002,[271,5415,...|\n",
      "|  ham|      * Am on my way|    14|  0.0|[*, am, on, my, way]|            [*, way]|(11001,[73,213],[...|(11001,[73,213],[...|(11002,[73,213,11...|(11002,[73,213,11...|\n",
      "|  ham|* Was really good...|    69|  0.0|[*, was, really, ...|[*, really, good,...|(11001,[15,33,43,...|(11001,[15,33,43,...|(11002,[15,33,43,...|(11002,[15,33,43,...|\n",
      "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_pipeline_2 = Pipeline(stages = [class_indexer, tokenizer, remover, cv, idf, assembler, scaler])\n",
    "\n",
    "pipe_trained = data_pipeline_2.fit(train)\n",
    "train = pipe_trained.transform(train)\n",
    "test = pipe_trained.transform(test)\n",
    "\n",
    "train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>label</th>\n",
       "      <th>token_text</th>\n",
       "      <th>stop_tokens</th>\n",
       "      <th>count_vec</th>\n",
       "      <th>tf_idf</th>\n",
       "      <th>features</th>\n",
       "      <th>scaled_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>&amp;lt;DECIMAL&amp;gt; m but its not a common car he...</td>\n",
       "      <td>132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[, &amp;lt;decimal&amp;gt;, m, but, its, not, a, commo...</td>\n",
       "      <td>[, &amp;lt;decimal&amp;gt;, m, common, car, better, bu...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 3.1021536787833863, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 3.1021536787833863, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 2.0960046808042807, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>said kiss, kiss, i can't do the sound effects...</td>\n",
       "      <td>133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[, said, kiss,, kiss,, i, can't, do, the, soun...</td>\n",
       "      <td>[, said, kiss,, kiss,, sound, effects!, gorgeo...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 3.1021536787833863, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 3.1021536787833863, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 2.0960046808042807, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>what number do u live at? Is it 11?</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[, what, number, do, u, live, at?, is, it, 11?]</td>\n",
       "      <td>[, number, u, live, at?, 11?]</td>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(2.0204432009178803, 0.0, 0.0, 3.1021536787833...</td>\n",
       "      <td>(2.0204432009178803, 0.0, 0.0, 3.1021536787833...</td>\n",
       "      <td>(1.8598083446711655, 0.0, 0.0, 2.0960046808042...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>\"Gimme a few\" was  &amp;lt;#&amp;gt;  minutes ago</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[\"gimme, a, few\", was, , &amp;lt;#&amp;gt;, , minutes,...</td>\n",
       "      <td>[\"gimme, few\", , &amp;lt;#&amp;gt;, , minutes, ago]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 6.204307357566773, 0.0, 0.0, 0...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 6.204307357566773, 0.0, 0.0, 0...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 4.192009361608561, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>\"Response\" is one of d powerful weapon 2 occup...</td>\n",
       "      <td>154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[\"response\", is, one, of, d, powerful, weapon,...</td>\n",
       "      <td>[\"response\", one, d, powerful, weapon, 2, occu...</td>\n",
       "      <td>(0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 5.367474836656289, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>(0.0, 0.0, 5.367474836656289, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>(0.0, 0.0, 6.091934415732526, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>spam</td>\n",
       "      <td>complimentary 4 STAR Ibiza Holiday or £10,000 ...</td>\n",
       "      <td>149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[complimentary, 4, star, ibiza, holiday, or, £...</td>\n",
       "      <td>[complimentary, 4, star, ibiza, holiday, £10,0...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.11338975...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.11338975...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.38357660...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>spam</td>\n",
       "      <td>dating:i have had two of these. Only started a...</td>\n",
       "      <td>139</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[dating:i, have, had, two, of, these., only, s...</td>\n",
       "      <td>[dating:i, two, these., started, sent, text, t...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>spam</td>\n",
       "      <td>important information 4 orange user 0789xxxxxx...</td>\n",
       "      <td>163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[important, information, 4, orange, user, 0789...</td>\n",
       "      <td>[important, information, 4, orange, user, 0789...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.11338975...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.11338975...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.38357660...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>spam</td>\n",
       "      <td>sexy sexy cum and text me im wet and warm and ...</td>\n",
       "      <td>144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[sexy, sexy, cum, and, text, me, im, wet, and,...</td>\n",
       "      <td>[sexy, sexy, cum, text, im, wet, warm, ready, ...</td>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(2.0204432009178803, 0.0, 2.6837374183281444, ...</td>\n",
       "      <td>(2.0204432009178803, 0.0, 2.6837374183281444, ...</td>\n",
       "      <td>(1.8598083446711655, 0.0, 3.045967207866263, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>spam</td>\n",
       "      <td>sports fans - get the latest sports news str* ...</td>\n",
       "      <td>153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[sports, fans, -, get, the, latest, sports, ne...</td>\n",
       "      <td>[sports, fans, -, get, latest, sports, news, s...</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 2.6837374183281444, 0.0, 2.84712177...</td>\n",
       "      <td>(0.0, 0.0, 2.6837374183281444, 0.0, 2.84712177...</td>\n",
       "      <td>(0.0, 0.0, 3.045967207866263, 0.0, 2.976723978...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1593 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class                                               text  length  label  \\\n",
       "0      ham   &lt;DECIMAL&gt; m but its not a common car he...     132    0.0   \n",
       "1      ham   said kiss, kiss, i can't do the sound effects...     133    0.0   \n",
       "2      ham                what number do u live at? Is it 11?      36    0.0   \n",
       "3      ham          \"Gimme a few\" was  &lt;#&gt;  minutes ago      41    0.0   \n",
       "4      ham  \"Response\" is one of d powerful weapon 2 occup...     154    0.0   \n",
       "...    ...                                                ...     ...    ...   \n",
       "1588  spam  complimentary 4 STAR Ibiza Holiday or £10,000 ...     149    1.0   \n",
       "1589  spam  dating:i have had two of these. Only started a...     139    1.0   \n",
       "1590  spam  important information 4 orange user 0789xxxxxx...     163    1.0   \n",
       "1591  spam  sexy sexy cum and text me im wet and warm and ...     144    1.0   \n",
       "1592  spam  sports fans - get the latest sports news str* ...     153    1.0   \n",
       "\n",
       "                                             token_text  \\\n",
       "0     [, &lt;decimal&gt;, m, but, its, not, a, commo...   \n",
       "1     [, said, kiss,, kiss,, i, can't, do, the, soun...   \n",
       "2       [, what, number, do, u, live, at?, is, it, 11?]   \n",
       "3     [\"gimme, a, few\", was, , &lt;#&gt;, , minutes,...   \n",
       "4     [\"response\", is, one, of, d, powerful, weapon,...   \n",
       "...                                                 ...   \n",
       "1588  [complimentary, 4, star, ibiza, holiday, or, £...   \n",
       "1589  [dating:i, have, had, two, of, these., only, s...   \n",
       "1590  [important, information, 4, orange, user, 0789...   \n",
       "1591  [sexy, sexy, cum, and, text, me, im, wet, and,...   \n",
       "1592  [sports, fans, -, get, the, latest, sports, ne...   \n",
       "\n",
       "                                            stop_tokens  \\\n",
       "0     [, &lt;decimal&gt;, m, common, car, better, bu...   \n",
       "1     [, said, kiss,, kiss,, sound, effects!, gorgeo...   \n",
       "2                         [, number, u, live, at?, 11?]   \n",
       "3           [\"gimme, few\", , &lt;#&gt;, , minutes, ago]   \n",
       "4     [\"response\", one, d, powerful, weapon, 2, occu...   \n",
       "...                                                 ...   \n",
       "1588  [complimentary, 4, star, ibiza, holiday, £10,0...   \n",
       "1589  [dating:i, two, these., started, sent, text, t...   \n",
       "1590  [important, information, 4, orange, user, 0789...   \n",
       "1591  [sexy, sexy, cum, text, im, wet, warm, ready, ...   \n",
       "1592  [sports, fans, -, get, latest, sports, news, s...   \n",
       "\n",
       "                                              count_vec  \\\n",
       "0     (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1     (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2     (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3     (0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n",
       "4     (0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "...                                                 ...   \n",
       "1588  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "1589  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1590  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "1591  (1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1592  (0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                 tf_idf  \\\n",
       "0     (0.0, 0.0, 0.0, 3.1021536787833863, 0.0, 0.0, ...   \n",
       "1     (0.0, 0.0, 0.0, 3.1021536787833863, 0.0, 0.0, ...   \n",
       "2     (2.0204432009178803, 0.0, 0.0, 3.1021536787833...   \n",
       "3     (0.0, 0.0, 0.0, 6.204307357566773, 0.0, 0.0, 0...   \n",
       "4     (0.0, 0.0, 5.367474836656289, 0.0, 0.0, 0.0, 0...   \n",
       "...                                                 ...   \n",
       "1588  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.11338975...   \n",
       "1589  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1590  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.11338975...   \n",
       "1591  (2.0204432009178803, 0.0, 2.6837374183281444, ...   \n",
       "1592  (0.0, 0.0, 2.6837374183281444, 0.0, 2.84712177...   \n",
       "\n",
       "                                               features  \\\n",
       "0     (0.0, 0.0, 0.0, 3.1021536787833863, 0.0, 0.0, ...   \n",
       "1     (0.0, 0.0, 0.0, 3.1021536787833863, 0.0, 0.0, ...   \n",
       "2     (2.0204432009178803, 0.0, 0.0, 3.1021536787833...   \n",
       "3     (0.0, 0.0, 0.0, 6.204307357566773, 0.0, 0.0, 0...   \n",
       "4     (0.0, 0.0, 5.367474836656289, 0.0, 0.0, 0.0, 0...   \n",
       "...                                                 ...   \n",
       "1588  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.11338975...   \n",
       "1589  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1590  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.11338975...   \n",
       "1591  (2.0204432009178803, 0.0, 2.6837374183281444, ...   \n",
       "1592  (0.0, 0.0, 2.6837374183281444, 0.0, 2.84712177...   \n",
       "\n",
       "                                        scaled_features  \n",
       "0     (0.0, 0.0, 0.0, 2.0960046808042807, 0.0, 0.0, ...  \n",
       "1     (0.0, 0.0, 0.0, 2.0960046808042807, 0.0, 0.0, ...  \n",
       "2     (1.8598083446711655, 0.0, 0.0, 2.0960046808042...  \n",
       "3     (0.0, 0.0, 0.0, 4.192009361608561, 0.0, 0.0, 0...  \n",
       "4     (0.0, 0.0, 6.091934415732526, 0.0, 0.0, 0.0, 0...  \n",
       "...                                                 ...  \n",
       "1588  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.38357660...  \n",
       "1589  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1590  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.38357660...  \n",
       "1591  (1.8598083446711655, 0.0, 3.045967207866263, 0...  \n",
       "1592  (0.0, 0.0, 3.045967207866263, 0.0, 2.976723978...  \n",
       "\n",
       "[1593 rows x 10 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.select(\"label\", \"scaled_features\")\n",
    "test = test.select(\"label\", \"scaled_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|     scaled_features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(11002,[3,81,128,...|[-2487.7633768525...|           [1.0,0.0]|       0.0|\n",
      "|  0.0|(11002,[3,115,200...|[-2395.5188627004...|           [1.0,0.0]|       0.0|\n",
      "|  0.0|(11002,[0,3,86,19...|[-798.40120183507...|[1.0,1.0453269184...|       0.0|\n",
      "|  0.0|(11002,[3,8,302,1...|[-415.41060815331...|[1.0,2.8823362140...|       0.0|\n",
      "|  0.0|(11002,[2,7,22,55...|[-2520.9205913190...|[1.0,3.6800840412...|       0.0|\n",
      "|  0.0|(11002,[0,5,10,33...|[-2262.0873761743...|[1.0,6.1645992048...|       0.0|\n",
      "|  0.0|(11002,[97,122,24...|[-413.52210074161...|[1.0,1.8854556421...|       0.0|\n",
      "|  0.0|(11002,[3,8,33,68...|[-3588.8353247867...|           [1.0,0.0]|       0.0|\n",
      "|  0.0|(11002,[3,8,294,6...|[-586.34290420575...|[1.0,1.9741630381...|       0.0|\n",
      "|  0.0|(11002,[8,216,249...|[-1149.9653022094...|[1.0,8.9954586443...|       0.0|\n",
      "|  0.0|(11002,[8,272,302...|[-2155.9969533232...|[1.0,3.6801253235...|       0.0|\n",
      "|  0.0|(11002,[5,17,76,1...|[-1233.9884183108...|[1.0,2.6870225254...|       0.0|\n",
      "|  0.0|(11002,[106,382,3...|[-1498.5365230038...|[1.0,1.5836609158...|       0.0|\n",
      "|  0.0|(11002,[19,22,115...|[-155.94666162761...|[1.0,1.0765249903...|       0.0|\n",
      "|  0.0|(11002,[44,213,11...|[-1994.2529867874...|[1.0,2.8280411624...|       0.0|\n",
      "|  0.0|(11002,[33,67,153...|[-285.18116650274...|[1.0,5.6301847661...|       0.0|\n",
      "|  0.0|(11002,[43,45,122...|[-1300.9079772721...|[1.0,1.6506380683...|       0.0|\n",
      "|  0.0|(11002,[0,213,369...|[-507.37829473147...|[1.0,6.6457929863...|       0.0|\n",
      "|  0.0|(11002,[0,2,3,7,2...|[-4701.3621197804...|           [1.0,0.0]|       0.0|\n",
      "|  0.0|(11002,[249,932,3...|[-1311.3311715751...|[1.0,1.6372566566...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = nb.fit(train)\n",
    "\n",
    "y_hat = model.transform(test)\n",
    "\n",
    "y_hat.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas en train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.996999768480733"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hat = model.transform(train)\n",
    "f1_evaluator = MulticlassClassificationEvaluator(predictionCol = \"prediction\", \n",
    "                                              labelCol = \"label\",\n",
    "                                              metricName = \"f1\")\n",
    "f1 = f1_evaluator.evaluate(train_hat)\n",
    "\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9969856819894499"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol = \"prediction\", \n",
    "                                              labelCol = \"label\",\n",
    "                                              metricName = \"accuracy\")\n",
    "accuracy = evaluator.evaluate(train_hat)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas en Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9613723626898588"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_evaluator = MulticlassClassificationEvaluator(predictionCol = \"prediction\", \n",
    "                                              labelCol = \"label\",\n",
    "                                              metricName = \"f1\")\n",
    "f1 = f1_evaluator.evaluate(y_hat)\n",
    "\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96045197740113"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol = \"prediction\", \n",
    "                                              labelCol = \"label\",\n",
    "                                              metricName = \"accuracy\")\n",
    "accuracy = evaluator.evaluate(y_hat)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackaboss",
   "language": "python",
   "name": "hackaboss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
